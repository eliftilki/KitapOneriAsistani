# KitapOneriAsistani
BERT ve T5 tabanlÄ± intent sÄ±nÄ±flandÄ±rmasÄ± kullanan Transformer tabanlÄ± akÄ±llÄ± bir kitap Ã¶neri sohbet botu

# ğŸ§  Chatbot AkÄ±ÅŸÄ± TasarÄ±mÄ±

![Chatbot AkÄ±ÅŸ DiyagramÄ±](homeworks\marmara\Elif_Tilki\chatbot_homework_elif_tilki\images\diagram.png)  
*YukarÄ±daki diyagram, chatbotun temel Ã§alÄ±ÅŸma prensibini ve kullanÄ±cÄ± ile etkileÅŸim sÃ¼recini gÃ¶rsel olarak Ã¶zetlemektedir.*

Chatbot, kullanÄ±cÄ±dan aldÄ±ÄŸÄ± girdiyi iÅŸleyerek anlamlandÄ±rmakta ve buna uygun yanÄ±tlarÄ± Ã¼retmektedir.

AkÄ±ÅŸ ÅŸu ÅŸekilde iÅŸlemektedir:  
Ã–ncelikle sistem baÅŸlatÄ±lÄ±r ve kullanÄ±cÄ±dan bir giriÅŸ alÄ±nÄ±r. KullanÄ±cÄ±nÄ±n yazdÄ±ÄŸÄ± cÃ¼mle, doÄŸal dil iÅŸleme iÃ§in tokenizer kullanÄ±larak parÃ§alara ayrÄ±lÄ±r. ArdÄ±ndan, BERT ya da T5 tabanlÄ± bir model ile kullanÄ±cÄ±nÄ±n niyeti (intent) tahmin edilir. Bu tahmin, Ã¶nceden tanÄ±mlanmÄ±ÅŸ intent listesinde kontrol edilir. EÄŸer tahmin edilen intent listede varsa, bu niyete karÅŸÄ±lÄ±k gelen cevaplar Excel dosyasÄ±ndan yÃ¼klenir ve aralarÄ±ndan rastgele bir yanÄ±t seÃ§ilerek kullanÄ±cÄ±ya gÃ¶sterilir. EÄŸer intent listede yoksa, chatbot Ã¶nceden belirlenmiÅŸ genel bir fallback (geri dÃ¶nÃ¼ÅŸ) cevabÄ± ile kullanÄ±cÄ±nÄ±n sorusuna yanÄ±t verir.

## ğŸ“‚ Veri Seti AÃ§Ä±klamasÄ±

Bu projede geliÅŸtirilen chatbot, **kitap Ã¶nerisi** konulu kullanÄ±cÄ± isteklerini anlayarak uygun yanÄ±tlar Ã¼retmektedir. Chatbotâ€™un eÄŸitimi ve deÄŸerlendirmesi iÃ§in Ã¶zel olarak hazÄ±rlanmÄ±ÅŸ bir veri seti kullanÄ±lmÄ±ÅŸtÄ±r.

---

### ğŸ” Veri Setinin AmacÄ±

AmaÃ§, kullanÄ±cÄ±dan gelen doÄŸal dil ifadelerini sÄ±nÄ±flandÄ±rarak, bunlara uygun kitap tÃ¼rÃ¼/tavsiyesi belirlemek ve buna gÃ¶re yanÄ±t Ã¼retmektir. Bu doÄŸrultuda, **Intent Classification** yaklaÅŸÄ±mÄ± kullanÄ±lmÄ±ÅŸtÄ±r.

---

### ğŸ“„ Veri FormatÄ± ve Ä°Ã§eriÄŸi

Veri seti `.xlsx` formatÄ±nda hazÄ±rlanmÄ±ÅŸ olup, her satÄ±rda bir Ã¶rnek kullanÄ±cÄ± cÃ¼mlesi ve buna karÅŸÄ±lÄ±k gelen bir *intent (niyet)* etiketi bulunmaktadÄ±r.
Bu projede toplam 24 farklÄ± intent etiketi kullanÄ±lmÄ±ÅŸtÄ±r. Her intentte 50 tane Ã¶rnek bulunmaktadÄ±r. Bu intentler arasÄ±nda kitap tÃ¼rlerine yÃ¶nelik isteklerin yanÄ± sÄ±ra sohbet (greeting, goodbye) ve bilinmeyen istekler iÃ§in Ã¶zel intentler de yer almaktadÄ±r:

**veri yapÄ±sÄ±:**

| Intent | Example |
|--------|--------|
| request_science_fiction_books | bilim kurgu klasiklerinden birkaÃ§ kitap Ã¶nerebilir misin |
| request_fantasy_books | fantastik evrenlerde geÃ§en kitaplar arÄ±yorum |
| request_historical_books | tarihi olaylarÄ± konu alan kitaplarÄ± severim, ne Ã¶nerirsin |
| request_detective_mystery_books | polisiye ve dedektiflik iÃ§eren romanlarÄ± seviyorum, ne Ã¶nerirsin |
| request_horror_books | korku ve gerilim unsurlarÄ± barÄ±ndÄ±ran kitaplar Ã¶nerir misin |
| request_romance_books | klasik aÅŸk romanlarÄ± Ã¶nerir misin |
| request_biography_books | biyografi tÃ¼rÃ¼nde etkileyici kitaplar var mÄ± |
| request_poetry_books | duygusal ÅŸiirleri iÃ§eren kitaplar var mÄ± |
| request_theater_books | tiyatro Ã¼zerine kÄ±sa oyun metinleri iÃ§eren kitaplar arÄ±yorum |
| request_comic_books | popÃ¼ler Ã§izgi roman serileri nelerdir |
| request_food_books | gourmet yemek tarifleri iÃ§eren kitaplar var mÄ± |
| request_chess_books | stratejik satranÃ§ oyun planlarÄ± hakkÄ±nda kitaplar arÄ±yorum |
| request_classic_books | klasik edebiyatÄ±n baÅŸyapÄ±tlarÄ± hangileridir |
| request_bestselling_books | bestseller listesinde hangi kitaplar var |
| request_self_improvement_books | kiÅŸisel geliÅŸimle ilgili etkili kitap Ã¶nerileri alabilir miyim |
| request_motivational_books | kendimi motive etmek iÃ§in okuyabileceÄŸim kitaplar hangileri |
| request_philosophical_books | felsefi akÄ±mlar ve dÃ¼ÅŸÃ¼nÃ¼rler Ã¼zerine kapsamlÄ± kitaplar arÄ±yorum |
| request_adventure_books | macera dolu hikayeler iÃ§eren kitaplar arÄ±yorum |
| request_educational_books | eÄŸitimle ilgili yeni Ã§Ä±kan kitaplar nelerdir |
| request_short_story_books | kÄ±sa hikaye tÃ¼rÃ¼nde en Ã§ok okunan kitaplar hangileri |
| request_kids_books | kÃ¼Ã§Ã¼k yaÅŸ gruplarÄ± iÃ§in kitap Ã¶nerileri verir misin |
| conversation_greeting | Merhaba, kitap Ã¶nerisi alabilir miyim?   |
| conversation_goodbye | TeÅŸekkÃ¼rler, hoÅŸÃ§a kal   |
| fallback_unknown_request | Åu an saat kaÃ§ |

- `request_...`: Belirli kitap tÃ¼rlerine yÃ¶nelik kullanÄ±cÄ± isteklerini temsil eder.

- `conversation_...`: Sohbetin doÄŸal akÄ±ÅŸÄ±nÄ± saÄŸlayan selamlaÅŸma/vedalaÅŸma niyetleridir.

- `fallback_unknown_request`: AnlaÅŸÄ±lmayan kullanÄ±cÄ± ifadeleri iÃ§in kullanÄ±lÄ±r.

Veri seti toplamda 1200 Ã¶rnek cÃ¼mle iÃ§ermektedir. Veri seti oluÅŸturulurken farklÄ± kitap tÃ¼rlerine yÃ¶nelik Ã§eÅŸitli kullanÄ±cÄ± ifadeleri tÃ¼retilmiÅŸtir. Verinin Ã¼retiminde, iÃ§erik Ã§eÅŸitliliÄŸini saÄŸlamak amacÄ±yla **yapay zekÃ¢ destekli otomatik veri Ã¼retim yÃ¶ntemlerinden** yararlanÄ±lmÄ±ÅŸtÄ±r (Ã¶rneÄŸin: LLM tabanlÄ± jenerasyon).

---

### âœ‚ï¸ Train/Test AyrÄ±mÄ±

Modelin eÄŸitimi ve doÄŸrulamasÄ± sÄ±rasÄ±nda **veri kaÃ§aÄŸÄ±nÄ± (data leakage)** Ã¶nlemek adÄ±na veri seti eÄŸitim ve test olarak ayrÄ±lmÄ±ÅŸtÄ±r. BÃ¶lme iÅŸlemi yapÄ±lÄ±rken sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n korunmasÄ± iÃ§in **Stratified Split** yÃ¶ntemi tercih edilmiÅŸtir.

Bu ayrÄ±m sonucunda:

- **EÄŸitim (Train) seti:** 960 Ã¶rnek (yani toplam verinin %80â€™i)  
- **Test seti:** 240 Ã¶rnek (toplam verinin %20â€™si)

**KullanÄ±lan Python kodu:**

```python
from sklearn.model_selection import train_test_split
import pandas as pd

df = pd.read_excel("book_recommendation_dataset_3.xlsx")
X = df['Example']
y = df['Intent']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

train_df = pd.DataFrame({'Example': X_train, 'Intent': y_train})
test_df = pd.DataFrame({'Example': X_test, 'Intent': y_test})

train_df.to_excel("train.xlsx", index=False)
test_df.to_excel("test.xlsx", index=False)
```
Bu kod sayesinde veriler `train.xlsx` ve `test.xlsx` olarak iki ayrÄ± dosyada saklanmÄ±ÅŸtÄ±r.

---

### ğŸ’¬ Intent-Cevap EÅŸleÅŸtirmesi

Modelin sadece doÄŸru intentâ€™i tahmin etmesi deÄŸil, aynÄ± zamanda **anlamlÄ± ve Ã§eÅŸitli yanÄ±tlar vermesi** hedeflenmiÅŸtir. Bu nedenle `intent_cevaplari.xlsx` adÄ±nda bir yardÄ±mcÄ± dosya hazÄ±rlanmÄ±ÅŸtÄ±r.

Her bir intent iÃ§in **beÅŸ farklÄ± yanÄ±t** oluÅŸturulmuÅŸ, bÃ¶ylece chatbotâ€™un daha **dinamik** ve **zengin** yanÄ±tlar Ã¼retebilmesi saÄŸlanmÄ±ÅŸtÄ±r.

**Ã–rnek yapÄ±:**

| Intent | Cevap1 | Cevap2 | Cevap3 | Cevap4 | Cevap5 |
|--------|--------|--------|--------|--------|--------|
| request_science_fiction_books | Bilim kurgu dÃ¼nyasÄ±nÄ±n klasikleri arasÄ±nda yer alan Isaac Asimovâ€™un "VakÄ±f" serisi... | ... | ... | ... | ... |

YanÄ±tlar, ilgili kitap tÃ¼rÃ¼ne dair Ã¶neriler sunacak ÅŸekilde **Ã§eÅŸitlendirilmiÅŸ** ve farklÄ± kullanÄ±cÄ± profillerine hitap edebilecek ÅŸekilde hazÄ±rlanmÄ±ÅŸtÄ±r.  

---

### ğŸ§  Ã–zet

- âœ… Veri seti toplamda 1200 Ã¶rnek cÃ¼mle iÃ§ermektedir.
- âœ… Veri, 24 farklÄ± intent etiketini kapsamaktadÄ±r.
- âœ… Veriler `.xlsx` formatÄ±nda dÃ¼zenlenmiÅŸ, **eÄŸitim ve test ayrÄ±mÄ±** yapÄ±lmÄ±ÅŸtÄ±r.
- âœ… Ek olarak, chatbotâ€™un yanÄ±t Ã¼retmesi iÃ§in **intent-yanÄ±t eÅŸleÅŸme tablosu** oluÅŸturulmuÅŸtur.
- âœ… Veri seti, projenin hem **eÄŸitimi** hem de **performans deÄŸerlendirmesi** aÅŸamalarÄ±nda kullanÄ±lmÄ±ÅŸtÄ±r.

# ğŸ§  Model SeÃ§imi ve EÄŸitimi

Bu projede iki farklÄ± Transformer tabanlÄ± dil modeli kullanÄ±larak chatbot amaÃ§lÄ± intent sÄ±nÄ±flandÄ±rmasÄ± gerÃ§ekleÅŸtirilmiÅŸtir: **BERT** ve **T5**. Bu modeller, doÄŸal dil iÅŸleme alanÄ±nda baÅŸarÄ±lÄ± performanslarÄ± ile bilinir ve farklÄ± Ã§alÄ±ÅŸma prensiplerine sahiptir.

---

## 1. BERT (Bidirectional Encoder Representations from Transformers)

- **Model**: `bert-base-uncased`  
- **KÃ¼tÃ¼phaneler**: Hugging Face Transformers, PyTorch  

### ğŸ” Ã‡alÄ±ÅŸma Prensibi

BERT, Ã§ift yÃ¶nlÃ¼ bir encoder modelidir. Girdi metnini anlamak iÃ§in tÃ¼m baÄŸlamÄ± aynÄ± anda deÄŸerlendirir. Bu projede intent sÄ±nÄ±flandÄ±rma iÃ§in son katmanÄ± fine-tune edilerek kullanÄ±lmÄ±ÅŸtÄ±r.

### ğŸ› ï¸ Veri Ä°ÅŸleme

- Tokenizer ile metinler tokenize edildi  
- Pad/Padding uygulandÄ±  
- Label mapping yapÄ±ldÄ±  

### âš™ï¸ EÄŸitim DetaylarÄ±

- **EÄŸitim OrtamÄ±**: Google Colab Pro, NVIDIA L4 GPU  
- **Epoch SayÄ±sÄ±**: 50 
- **Ã‡alÄ±ÅŸan Epoch SayÄ±sÄ±**: 17 (erken durdurma ile) 
- **EÄŸitim SÃ¼resi**: YaklaÅŸÄ±k 4 dakika  
- **Batch Size**: 16  
- **Learning Rate**: 2e-5  
- **Erken Durdurma**: KullanÄ±ldÄ±
- 
### âœ… Avantajlar

- SÄ±nÄ±flandÄ±rma gÃ¶revlerinde yÃ¼ksek doÄŸruluk  
- Stabil sonuÃ§lar  

### ğŸ“‰ Confusion Matrix - BERT

![BERT Confusion Matrix](homeworks\ChatbotGelistirme\elif_tilki\images\bert_conf_matrix.png)

---

## 2. T5 (Text-to-Text Transfer Transformer)

- **Model**: `google/flan-t5-base`  
- **KÃ¼tÃ¼phaneler**: Hugging Face Transformers, PyTorch  

### ğŸ” Ã‡alÄ±ÅŸma Prensibi

T5, metni metne Ã§eviren bir modeldir. Intent sÄ±nÄ±flandÄ±rma iÃ§in giriÅŸ `"classify intent: <metin>"` formatÄ±nda verilir, model de doÄŸrudan intent etiketini Ã¼retir.

### ğŸ› ï¸ Veri Ä°ÅŸleme

- Girdi ve Ã§Ä±ktÄ± metinleri tokenizer ile uygun uzunlukta tokenize edildi  
- Padding uygulandÄ±  
- Output label'lar iÃ§in `-100` maskesi kullanÄ±ldÄ±  

### âš™ï¸ EÄŸitim DetaylarÄ±

- **EÄŸitim OrtamÄ±**: Google Colab Pro, NVIDIA L4 GPU  
- **Epoch SayÄ±sÄ±**: 50
- **Ã‡alÄ±ÅŸan Epoch SayÄ±sÄ±**: 43 (erken durdurma ile)  
- **EÄŸitim SÃ¼resi**: YaklaÅŸÄ±k 17 dakika  
- **Batch Size**: 16  
- **Learning Rate**: 2e-5  
- **Erken Durdurma**: KullanÄ±ldÄ±  

### âœ… Avantajlar

- Daha esnek metin Ã¼retimi  
- FarklÄ± gÃ¶revlerde yeniden kullanÄ±labilirlik  

### ğŸ“‰ Confusion Matrix - T5

![T5 Confusion Matrix](homeworks\ChatbotGelistirme\elif_tilki\images\t5_conf_matrix.png) 

---

## ğŸ” KarÅŸÄ±laÅŸtÄ±rma ve DeÄŸerlendirme

| Model | Precision | Recall | F1 Score |Accuracy| 
|-------|-----------|--------|----------|--------|
| BERT  | 0.9495    | 0.9458 | 0.9450   | 0.95   | 
| T5    | 0.8683    | 0.8538 | 0.8547   | 0.93   |

Her iki model de aynÄ± eÄŸitim ve test verisiyle karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Performans metriÄŸi olarak **Precision**, **Recall** ve **F1 Score** dikkate alÄ±nmÄ±ÅŸtÄ±r. 
Adil bir karÅŸÄ±laÅŸtÄ±rma yapÄ±labilmesi iÃ§in her iki modelde de aynÄ± batch size (16) ve aynÄ± learning rate (2e-5) kullanÄ±lmÄ±ÅŸtÄ±r. Epoch sayÄ±sÄ±, erken durdurma kriterlerine baÄŸlÄ± olarak farklÄ±lÄ±k gÃ¶stermektedir.
**BERT** modeli biraz daha yÃ¼ksek baÅŸarÄ± gÃ¶sterirken, **T5** modelinin esnekliÄŸi ve text-to-text yapÄ±sÄ± farklÄ± kullanÄ±m senaryolarÄ± iÃ§in avantaj saÄŸlamaktadÄ±r.

### Genel Performans

**BERT** modeli, tÃ¼m metriklerde **T5** modelinden daha yÃ¼ksek skorlar elde etmiÅŸtir. Ã–zellikle:

- **Precision (DoÄŸruluk):**  
  BERT, daha az yanlÄ±ÅŸ pozitif tahmin yaparak **%95**'e yakÄ±n bir doÄŸruluk saÄŸlamÄ±ÅŸtÄ±r.

- **Recall (DuyarlÄ±lÄ±k):**  
  GerÃ§ek sÄ±nÄ±flarÄ± bulmadaki baÅŸarÄ±sÄ± da BERTâ€™te daha yÃ¼ksektir. Bu da chatbotâ€™un kullanÄ±cÄ± niyetlerini kaÃ§Ä±rma oranÄ±nÄ±n daha dÃ¼ÅŸÃ¼k olduÄŸu anlamÄ±na gelir.

- **F1 Score:**  
  Hem precision hem recallâ€™u dengeleyen bu metrikte de BERT **%94.5** ile Ã¶ne Ã§Ä±kmaktadÄ±r.

- **Accuracy:**  
  Genel doÄŸru tahmin oranÄ± BERT iÃ§in **%95**, T5 iÃ§in **%93**â€™tÃ¼r.


### DetaylÄ± GÃ¶zlemler

- **T5** modelinde bazÄ± sÄ±nÄ±flar hiÃ§ temsil edilmemiÅŸtir (`support = 0`).  
  Bu durum, modelin bu sÄ±nÄ±flarla ilgili yeterli eÄŸitilmediÄŸini ya da Ã§Ä±ktÄ±larÄ±nÄ±n sÄ±nÄ±flandÄ±rma aÃ§Ä±sÄ±ndan eksik kaldÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

- Her iki modelde de `"request_fantasy_books"` ve `"request_science_fiction_books"` gibi bazÄ± sÄ±nÄ±flarda **recall oranÄ±** diÄŸerlerine kÄ±yasla daha dÃ¼ÅŸÃ¼ktÃ¼r.  
  Bu durum, bu tÃ¼r cÃ¼mlelerin model tarafÄ±ndan daha karmaÅŸÄ±k veya Ã¶rtÃ¼k bulunabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼rebilir.


### SonuÃ§ ve Ã–neri

Bu deÄŸerlendirme, **BERT** tabanlÄ± modelin kitap Ã¶neri chatbotu uygulamasÄ± iÃ§in daha **uygun ve gÃ¼venilir** bir seÃ§im olduÄŸunu gÃ¶stermektedir.

- DoÄŸru sÄ±nÄ±flandÄ±rma oranÄ± daha yÃ¼ksektir.
- YanlÄ±ÅŸ pozitif/negatif oranlarÄ± daha dÃ¼ÅŸÃ¼ktÃ¼r.

**T5**, daha yaratÄ±cÄ± ve jeneratif gÃ¶revlerde baÅŸarÄ±lÄ± bir model olsa da, bu gÃ¶revde sÄ±nÄ±flandÄ±rma kabiliyetinde BERTâ€™e kÄ±yasla geri planda kalmÄ±ÅŸtÄ±r.  

---

## âš™ï¸ EÄŸitim SÃ¼reci ve AraÃ§lar

- **API ve AraÃ§lar**: Hugging Face Transformers, PyTorch  
- **DonanÄ±m**: Google Colab Pro, NVIDIA L4 GPU  
- **Model Kaydetme**: AÄŸÄ±rlÄ±klar ve label-id eÅŸlemeleri eÄŸitim sonunda kaydedildi  
- **Erken Durdurma**: Overfittingâ€™i Ã¶nlemek iÃ§in kullanÄ±ldÄ±  

## ğŸ–¥ï¸ Uygulama ArayÃ¼zÃ¼

Chatbot sistemine kullanÄ±cÄ± etkileÅŸimi kazandÄ±rmak amacÄ±yla **Streamlit** tabanlÄ± bir web arayÃ¼zÃ¼ geliÅŸtirilmiÅŸtir. Bu arayÃ¼z sayesinde kullanÄ±cÄ±lar, doÄŸal dilde kitap Ã¶nerisi taleplerini yazabilir ve chatbotâ€™un gerÃ§ek zamanlÄ± yanÄ±tlarÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyebilirler.

---

## âš™ï¸ ArayÃ¼zÃ¼n Temel Ã–zellikleri

- KullanÄ±cÄ±dan serbest metin giriÅŸi alÄ±nÄ±r.
- KullanÄ±cÄ±, iki modelden birini (**BERT** veya **T5**) seÃ§ebilir.
- SeÃ§ilen model, girdiye uygun intent'i (niyeti) sÄ±nÄ±flandÄ±rÄ±r.
- Belirlenen intentâ€™e uygun, Ã¶nceden tanÄ±mlanmÄ±ÅŸ cevaplardan rastgele biri kullanÄ±cÄ±ya gÃ¶sterilir.
- Hangi niyetin sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ± kullanÄ±cÄ±ya aÃ§Ä±klanÄ±r (ğŸ¯ **Niyet: ...**).
- Sayfa tasarÄ±mÄ±, kullanÄ±cÄ± deneyimini artÄ±rmak iÃ§in Ã¶zel CSS ile Ã¶zelleÅŸtirilmiÅŸtir.

---

## ğŸ“ KullanÄ±lan Dosyalar ve Gereksinimler

ArayÃ¼zÃ¼n saÄŸlÄ±klÄ± Ã§alÄ±ÅŸabilmesi iÃ§in aÅŸaÄŸÄ±daki dosya ve dizinlerin proje yapÄ±sÄ±nda doÄŸru ÅŸekilde konumlandÄ±rÄ±lmasÄ± gerekmektedir:

| Dosya / Dizin         | AÃ§Ä±klama                                                                 |
|------------------------|--------------------------------------------------------------------------|
| `streamlit_app.py`     | Streamlit tabanlÄ± arayÃ¼zÃ¼ Ã§alÄ±ÅŸtÄ±ran ana dosya.                         |
| `./bert_output/`       | EÄŸitilmiÅŸ BERT modelinin aÄŸÄ±rlÄ±klarÄ±nÄ± iÃ§erir.                          |
| `./best_t5_model/`     | EÄŸitilmiÅŸ T5 modelinin aÄŸÄ±rlÄ±klarÄ±nÄ± iÃ§erir.                            |
| `intent_cevaplari.xlsx`| Her intent iÃ§in farklÄ± cevaplarÄ± iÃ§eren Excel dosyasÄ±.                  |
| `label2id.pkl`         | BERT modeline Ã¶zel intent-id eÅŸlemesini iÃ§eren pickle dosyasÄ±.          |

---

## ğŸ§ª Model SeÃ§imi Ã–zelliÄŸi

ArayÃ¼zde kullanÄ±cÄ±ya `"BERT"` veya `"T5"` modellerinden birini seÃ§me imkÃ¢nÄ± sunulmuÅŸtur. SeÃ§ilen modele gÃ¶re uygun chatbot sÄ±nÄ±fÄ± yÃ¼klenir ve cevaplama sÃ¼reci bu modele gÃ¶re Ã§alÄ±ÅŸÄ±r.  
AyrÄ±ca, **Streamlit**â€™in `@st.cache_resource` dekoratÃ¶rÃ¼ sayesinde model sadece bir kez yÃ¼klenir, bÃ¶ylece sistem performansÄ± optimize edilir.

---

## ğŸ“¥ KullanÄ±m Ã–rneÄŸi

ArayÃ¼zÃ¼ baÅŸlatmak iÃ§in terminalde aÅŸaÄŸÄ±daki komut Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r:

```bash
streamlit run streamlit_chatbot_app.py
```
AÃ§Ä±lan web arayÃ¼zÃ¼nde:

1. **Model seÃ§ilir** (`BERT` veya `T5`)
2. AÅŸaÄŸÄ±daki gibi bir mesaj yazÄ±lÄ±r:

    ```text
    Macera dolu bir kitap Ã¶nerir misin?
    ```

3. Model, bu girdi Ã¼zerinden ilgili intentâ€™i (Ã¶rneÄŸin `Adventure`) tanÄ±mlar ve uygun cevabÄ± Ã¼retir.
4. Sohbet ekranÄ±nda hem yanÄ±t hem de sÄ±nÄ±flandÄ±rÄ±lan niyet aÅŸaÄŸÄ±daki ÅŸekilde gÃ¶rÃ¼ntÃ¼lenir:

    ```text
    YanÄ±t: Jules Verneâ€™in Denizler AltÄ±nda Yirmi Bin Fersah kitabÄ±, denizaltÄ± maceralarÄ±nÄ± sevenler iÃ§in heyecan dolu ve sÃ¼rÃ¼kleyici bir klasik olarak Ã¶nerilir.
    ğŸ¯ Niyet: request_adventure_books
    ```

---

## ğŸ“¸ Ekran GÃ¶rÃ¼ntÃ¼leri

AÅŸaÄŸÄ±da uygulamanÄ±n farklÄ± kullanÄ±m senaryolarÄ±na ait Ã¶rnek ekran gÃ¶rÃ¼ntÃ¼leri sunulmuÅŸtur:

- ğŸ¨ **Genel ArayÃ¼z GÃ¶rÃ¼nÃ¼mÃ¼**  
  ![Genel ArayÃ¼z](homeworks\ChatbotGelistirme\elif_tilki\images\arayuz_genel.PNG)

- ğŸ¤– **BERT Modeli ile Sohbet**  
  ![BERT Sohbet](homeworks\ChatbotGelistirme\elif_tilki\images\bert_sohbet.PNG)

- ğŸ¤– **T5 Modeli ile Sohbet**  
  ![T5 Sohbet](homeworks\ChatbotGelistirme\elif_tilki\images\t5_sohbet.PNG)



